---
title: "Initial Analysis"
author: "Vivek Katial"
date: "27/05/2020"
output: 
  html_document:
    toc: true
  pdf_document:
    toc: true
editor_options: 
  chunk_output_type: console
---

## Introduction

This analysis looks into a building a model to for understanding $\mathbb{P}(\text{success})$.

We first need to get the data from `mlflow`. This analysis goes into detail on the steps required to go from loading the data to building various models. We also conduct an EDA on the instance features.

## Set up Environment

- Below is the code to load all the packages and files to set up the environment.
- We also load the "enriched" data into our environment.

```{r setup, warning=FALSE, message=FALSE, error=FALSE}
# Import libraries
library(here)
library(igraph)
library(cowplot)
library(grid)
library(gridExtra)
library(rpart)
library(randomForest)
library(modelr)
library(tidyverse)
library(GGally)
library(RColorBrewer)
library(corrplot)

# Set knitr options
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F, error = F, fig.align = 'center', fig.width = 10)

# Source in relavent scripts
source(here("utils/mlflow-utils.R"))
source(here("utils/plotting-utils.R"))
source(here("analysis/enrichments/variable-clause-graph.R"))
source(here("analysis/enrichments/variable-graph.R"))

# Load in enriched data
d_enriched <- read_rds(here("data/d_enriched.rds"))
d_runs <- get_mlflow_data(here("data/d_runs.csv"))
```


Our enriched dataset has a naming convention based on the prefix in each column, we describe the numeric columns below:

- `metrics_<METRIC>`: With the exception of `metrics_clause_var_ratio` (Clause to variable ratio), these are metrics which are calculated **during** our simulation and cannot be calculated prior to evolving our system.
- `params_<PARAMETER>`: With the exception of `params_instance_index` (Index for randomly generated problem), these are input parameters to our system's evolution
- `f_p_size_<FEATURE>`: These are features related to the *problem size* of our instance.
- `f_vcg_<FEATURE>`: These are features related to the *variable clause graph* of our instance.
- `f_vg_<FEATURE>`: These are features related to the *variable graph* of our instance

### Variable Clause Graph

Variable-Clause Graph (VCG) is a bipartite graph with a node for each variable, a node for each clause, and an edge between them whenever a variable occurs in a clause.

```{r}
example_d_clauses = list(
  k_1 = c(1L, 3L, 4L),
  k_2 = c(1L, 5L, 6L),
  k_3 = c(1L, 4L, 6L),
  k_4 = c(2L, 5L, 6L),
  k_5 = c(1L, 2L, 5L)
  )

colrs = c("tomato", "gold")
example_qubits = 6
example_var_clause_graph = make_variable_clause_graph(d_clauses = example_d_clauses, example_qubits, ret.all = T)


ggnet2(example_var_clause_graph$vcg, color = "color", palette = "Set2") +
    scale_color_brewer(
      "", 
      palette = "Set1",
      labels = c("tomato" = "Variable", "gold" = "Clause"),
      guide = guide_legend(override.aes = list(size = 6))
    )
```

### Variable Graph
Variable Graph (VG) has a node for each variable and an edge between variables that occur together in at least one clause.

```{r}
example_d_clauses = list(
  k_1 = c(1L, 3L, 4L),
  k_2 = c(1L, 5L, 6L),
  k_3 = c(1L, 4L, 6L),
  k_4 = c(2L, 5L, 6L),
  k_5 = c(1L, 2L, 5L)
)

example_qubits = 6

d_clauses = example_d_clauses
n_qubits = example_qubits

var_graph = make_variable_graph(example_d_clauses, example_qubits)
ggnet2(var_graph)
```

## Normalise Data

Before modelling we need to ensure that each configuration of parameters has the same number of randomly generated samples. We will only take runs that have had atleast $n=5$ completed runs. We will also enrich another column called `use_config (bool)`. This column will indicate whether that instance should be used in our analysis.

```{r}
min_runs <- 10

# Find run configs with more than n=min_runs
d_configs <- d_enriched %>% 
  select_if(is.numeric) %>% 
  select(starts_with("params")) %>% 
  count(params_n_qubits, params_time_t, params_t_step) %>% 
  arrange(n) %>% 
  filter(n >= min_runs) %>% 
  mutate(load = T)

d_sampled <- d_enriched %>% 
  left_join(d_configs, by = c("params_n_qubits", "params_time_t", "params_t_step")) %>% 
  filter(load == T) %>% 
  group_by(params_n_qubits, params_time_t, params_t_step) %>% 
  sample_n(min_runs) %>% 
  select(-experiment_id, -n) %>% 
  ungroup()
```

# Experiments Run

Before we start building a model it's useful to have a look at what experiments have ran so far.

```{r}
d_runs %>% 
  count(params_n_qubits, params_t_step,params_instance_type, params_time_t) %>% 
  arrange(n) %>% 
  ggplot(aes(x = as.factor(params_n_qubits), y = n, fill = as.factor(params_time_t))) + 
  geom_col(aes(fill = as.factor(params_time_t)), position = position_dodge(width = 0.9)) +
  geom_text(aes(label = n), position = position_dodge(width = 0.9), vjust = -0.7, size = 2.6) + 
  scale_fill_brewer(palette = "Blues", name = "Evolution Time") +
  theme_light() +
  facet_wrap(c("params_t_step", "params_instance_type")) + 
  theme(
    legend.position = "bottom"
  ) + 
  labs(
    x = "n qubits",
    y = "Number of runs",
    title = "Summary of Experiments Run "
  )
```

Great, now when we sample our dataset, we see each column has the same number of completed runs in our case `r min_runs`.

```{r}
d_sampled %>% 
  count(params_n_qubits, params_t_step, params_time_t,params_instance_type) %>% 
  arrange(n) %>% 
  ggplot(aes(x = as.factor(params_n_qubits), y = n, fill = as.factor(params_time_t))) + 
  geom_col(aes(fill = as.factor(params_time_t)), position = position_dodge(width = 0.9)) +
  geom_text(aes(label = n), position = position_dodge(width = 0.9), vjust = -0.7, size = 2.6) + 
  scale_fill_brewer(palette = "Blues", name = "Evolution Time") +
  theme_light() +
  facet_wrap(c("params_t_step", "params_instance_type")) + 
  theme(
    legend.position = "bottom"
  ) + 
  labs(
    x = "n qubits",
    y = "Number of runs",
    title = "Summary of Experiments Run "
  )
```

## Energy and Entanglement vs Number of Qubits

```{r}

d_sampled %>% 
  group_by(params_n_qubits, params_instance_type) %>% 
  summarise(
    entanglement = mean(metrics_max_shannon_entropy,na.rm = T),
    min_energy = mean(metrics_min_energy_gap, na.rm = T)
  ) %>% 
  gather(metric, value, -params_n_qubits, -params_instance_type) %>% 
  ggplot(aes(x = params_n_qubits, y = value, col = params_instance_type)) + 
  geom_line() + 
  facet_wrap(~metric, scales = "free", ncol = 1) + 
  theme_light() +
  labs(
    x = "N Qubits",
    y = "Value"
  )
```

## Shannon Entropy vs Clause-to-variable ratio (by qubits)

We notice that for a smaller number of qubits we have almost no variance in the number of instances generated (this is noticed by clause-to-variable-ratio). We also see that our maximum shannon entropy *decreases* as we run our evolution longer.

```{r}
d_enriched %>% 
  select(
    metrics_clause_var_ratio, 
    metrics_min_energy_gap, 
    metrics_max_shannon_entropy, 
    params_n_qubits, 
    params_time_t,
    params_instance_type
  ) %>%
  mutate(
    params_n_qubits = as.factor(params_n_qubits)
    ) %>% 
  ggplot(aes(x = metrics_clause_var_ratio, y = metrics_max_shannon_entropy, col = params_instance_type)) +
  geom_point(alpha = 0.8) + 
  facet_wrap(~params_n_qubits) + 
  theme_light() + 
  labs(
    x = "Clause-Variable Ratio",
    y = "Max Shannon Entropy",
    title = "Shannon Entropy vs Clause-Var Ratio (by qubits)"
  )
```

## $\mathbb{P}(\text{success})$ over T

One of the key metrics we're interested in is $\mathbb{P}(\text{success})$. As we see probability of sucess increasing as the evolution run time of the algorithm  continues, we observe a higher  $\mathbb{P}(\text{success})$. We also observe a higher variance.

```{r}
d_enriched %>% 
  select(metrics_p_success, params_n_qubits, params_time_t, params_t_step, params_instance_type) %>% 
  mutate(
    params_time_t = as.numeric(params_time_t),
    params_t_step = as.factor(params_t_step)
  ) %>% 
  ggplot(aes(x = params_time_t, y = metrics_p_success, col = params_instance_type)) + 
  geom_point(alpha = 0.5) + 
  facet_wrap(~as.numeric(params_n_qubits)) +
  labs(
    y = "Probability of Success",
    x = "Evolution Time"
  ) + 
  theme_light()
```

## Shannon Entropy vs  $\mathbb{P}(\text{success})$ (by T)

Here we clearly observe that a lower shannon entropy corresponds to a higher probability of success, but this may also be confounded due to the algorithm run time, $T$.

```{r}
d_sampled %>% 
  select(metrics_p_success, metrics_max_shannon_entropy, params_time_t, params_instance_type) %>% 
  ggplot(aes(x = metrics_p_success, y = metrics_max_shannon_entropy, col = params_instance_type)) + 
  geom_point(alpha = 0.5) +
  labs(
    x = "Probability of Success",
    y = "Shannon Entropy"
  ) +
  facet_wrap(~params_time_t) +
  theme_light()

d_sampled %>% 
  select(
    metrics_p_success, 
    metrics_max_shannon_entropy, 
    params_time_t, 
    params_n_qubits, 
    params_instance_type
    ) %>% 
  ggplot(aes(x = metrics_p_success, y = metrics_max_shannon_entropy, col = params_instance_type)) + 
  geom_point(alpha = 0.6) +
  facet_wrap(c("params_n_qubits", "params_time_t"),  labeller = label_wrap_gen(multi_line=FALSE)) + 
  labs(
    x = "Probability of Success",
    y = "Shannon Entropy",
    title = " P(success) vs Entropy (by Qubits)"
  ) +
  theme_light()
```

##  Min Energy Gap vs $\mathbb{P}(\text{success})$

```{r}
d_sampled %>% 
  select(metrics_p_success, metrics_min_energy_gap, params_time_t, params_instance_type) %>% 
  ggplot(aes(x = metrics_p_success, y = metrics_min_energy_gap, col = params_instance_type)) + 
  geom_point(alpha = 0.6) +
  theme_light() +
  facet_wrap(~params_time_t) +
  labs(
    x = "Probability of Success",
    y = "Min Energy Gap",
    title =  "P(success) vs Min Energy Gap"
  )

d_sampled %>% 
  select(metrics_p_success, metrics_min_energy_gap, params_time_t, params_n_qubits, params_instance_type) %>% 
  ggplot(aes(x = metrics_p_success, y = metrics_min_energy_gap, col = params_instance_type)) + 
  geom_point(alpha = 0.8) +
  facet_wrap(~params_n_qubits+params_time_t, labeller = label_wrap_gen(multi_line=FALSE)) + 
  theme_light() + 
  labs(
    x = "Probability of Success",
    y = "Min Energy Gap",
    title = "P(Success) vs Energy Gap (by Qubit)"
  )
```

## Clause to Var Ratio vs $\mathbb{P}(\text{success})$

```{r}
d_sampled %>% 
  select(
    metrics_p_success, 
    metrics_clause_var_ratio, 
    params_n_qubits, 
    params_time_t, 
    params_instance_type
    ) %>% 
  ggplot(aes(x = metrics_clause_var_ratio, y = metrics_p_success, col = params_instance_type)) + 
  geom_point() + 
  facet_wrap(~params_n_qubits) +
  theme_light() + 
  labs(
    x = "Clause-Variable Ratio",
    y = "P(Success)"
  )
```


<!-- # Modelling $\mathbb{P}(\text{success})$ -->

<!-- We can now begin to model $\mathbb{P}(\text{success})$, let's start off with a simple linear model. -->

<!-- First we need to remove columns with no standard deviation and also ones with missing values. -->

<!-- We can now checkout a correlation matrix. -->
<!-- ```{r} -->
<!-- # Model for p_success -->
<!-- d_model_ps <- d_sampled %>%  -->
<!--   select_if(is.numeric) %>%  -->
<!--   select(-starts_with(c("metric", "params")), metrics_p_success) %>%  -->
<!--   filter_all(all_vars(!is.na(.))) %>%  -->
<!--   Filter(f = sd, .) -->

<!-- M <-cor(d_model_ps) -->
<!-- corrplot( -->
<!--   M,  -->
<!--   type="upper",  -->
<!--   order="original", -->
<!--   col=brewer.pal(n=8, name="RdYlBu"), -->
<!--   tl.cex = 0.5, -->
<!--   tl.col = "blue" -->
<!--   ) -->
<!-- ``` -->

<!-- Ok we can see a bunch of these features are completely correlated with each other. -->

<!-- ## Simple Linear Regression -->

<!-- Let's start off with a basic `lm`. -->
<!-- ```{r} -->
<!-- model_ps_lm <- d_model_ps %>%  -->
<!--   lm(formula = metrics_p_success ~ ., data = .) -->

<!-- summary(model_ps_lm) -->
<!-- ``` -->

<!-- Ok, horrible fit! We also see all the linearised ratio terms are `NA` due to singularities. -->

<!-- ```{r} -->
<!-- model_ps_lm_1 <- d_model_ps %>%  -->
<!--   select(-f_p_size_lin_ratio, -f_p_size_lin_ratio_sq, -f_p_size_lin_ratio_cb) %>%  -->
<!--   lm(formula = metrics_p_success ~ ., data = .) -->

<!-- summary(model_ps_lm_1) -->
<!-- ``` -->

<!-- We still see a terrible fit. -->

<!-- ```{r} -->
<!-- model_ps_lm_1 %>%  -->
<!--   add_predictors(.) -->

<!-- ``` -->
<!-- ## Decision Tree (Regression) -->

<!-- ```{r} -->
<!-- m_fit <- d_model %>%  -->
<!--   rpart(metrics_p_success ~ ., method="anova", data= .) -->

<!-- printcp(m_fit) # display the results -->
<!-- plotcp(m_fit) # visualize cross-validation results -->
<!-- summary(m_fit) # detailed summary of splits -->

<!-- # create additional plots -->
<!-- par(mfrow=c(1,2)) # two plots on one page -->
<!-- rsq.rpart(m_fit) # visualize cross-validation results   -->
<!-- # plot tree -->
<!-- plot(m_fit, uniform=TRUE, -->
<!--    main="Regression Tree for Probability of Success ") -->
<!-- text(m_fit, use.n=TRUE, all=TRUE, cex=.8) -->
<!-- ``` -->

<!-- ## Random Forest -->

<!-- Let's look at the model summary: -->




<!-- ## XGBoost (eXtreme Gradient Boosted Trees) -->

<!-- # Features - Problems Size -->

<!-- ## Problem Size Features w.r.t $\mathbb{P}(\text{success})$ -->

<!-- ```{r, echo=F, results=F} -->
<!-- p_size_features <- d_sampled %>%  -->
<!--   select(contains("f_p_size")) %>%  -->
<!--   names() -->

<!-- lapply(p_size_features, function(x){ -->
<!--   generate_feature_plot( -->
<!--     data = d_sampled, -->
<!--     metric = "metrics_p_success", -->
<!--     feature = x -->
<!--     ) -->
<!-- }) -->
<!-- ``` -->

<!-- ## Problem Size Features w.r.t Shannon Entropy -->

<!-- ```{r, echo=F, results=F} -->
<!-- p_size_features <- d_sampled %>%  -->
<!--   select(contains("f_p_size")) %>%  -->
<!--   names() -->

<!-- lapply(p_size_features, function(x){ -->
<!--   generate_feature_plot( -->
<!--     data = d_sampled, -->
<!--     metric = "metrics_max_shannon_entropy", -->
<!--     feature = x -->
<!--     ) -->
<!-- }) -->
<!-- ``` -->

<!-- ## Problem Size Features w.r.t Min Energy Gap -->

<!-- ```{r, echo=F, results=F} -->
<!-- p_size_features <- d_sampled %>%  -->
<!--   select(contains("f_p_size")) %>%  -->
<!--   names() -->

<!-- lapply(p_size_features, function(x){ -->
<!--   generate_feature_plot( -->
<!--     data = d_sampled, -->
<!--     metric = "metrics_min_energy_gap", -->
<!--     feature = x -->
<!--     ) -->
<!-- }) -->
<!-- ``` -->

<!-- # Features - Variable Clause Graph -->

<!-- ## Variable Clause Graph Features w.r.t $\mathbb{P}(\text{success})$ -->

<!-- ```{r, echo=F, results=F} -->
<!-- vcg_features <- d_sampled %>%  -->
<!--   select(contains("f_vcg_")) %>%  -->
<!--   names() -->

<!-- lapply(vcg_features, function(x){ -->
<!--   generate_feature_plot( -->
<!--     data = d_sampled, -->
<!--     metric = "metrics_p_success", -->
<!--     feature = x -->
<!--     ) -->
<!-- }) -->
<!-- ``` -->

<!-- ## Variable Clause Graph Features w.r.t Shannon Entropy -->

<!-- ```{r, echo=F, results=F} -->
<!-- vcg_features <- d_sampled %>%  -->
<!--   select(contains("f_vcg_")) %>%  -->
<!--   names() -->

<!-- lapply(vcg_features, function(x){ -->
<!--   generate_feature_plot( -->
<!--     data = d_sampled, -->
<!--     metric = "metrics_max_shannon_entropy", -->
<!--     feature = x -->
<!--     ) -->
<!-- }) -->
<!-- ``` -->

<!-- ## Variable Clause Graph Features w.r.t Min Energy Gap -->

<!-- ```{r, echo=F, results=F} -->
<!-- vcg_features <- d_sampled %>%  -->
<!--   select(contains("f_vcg_")) %>%  -->
<!--   names() -->

<!-- lapply(vcg_features, function(x){ -->
<!--   generate_feature_plot( -->
<!--     data = d_sampled, -->
<!--     metric = "metrics_min_energy_gap", -->
<!--     feature = x -->
<!--     ) -->
<!-- }) -->
<!-- ``` -->

<!-- # Features - Variable Graph -->

<!-- ## Variable Graph Features w.r.t $\mathbb{P}(\text{success})$ -->

<!-- ```{r, echo=F, results=F} -->
<!-- vg_features <- d_sampled %>%  -->
<!--   select(contains("f_vg_")) %>%  -->
<!--   names() -->

<!-- lapply(vg_features, function(x){ -->
<!--   generate_feature_plot( -->
<!--     data = d_sampled, -->
<!--     metric = "metrics_p_success", -->
<!--     feature = x -->
<!--     ) -->
<!-- }) -->
<!-- ``` -->

<!-- ## Variable Graph Features w.r.t Shannon Entropy -->

<!-- ```{r, echo=F, results=F} -->
<!-- vg_features <- d_sampled %>%  -->
<!--   select(contains("f_vg_")) %>%  -->
<!--   names() -->

<!-- lapply(vg_features, function(x){ -->
<!--   generate_feature_plot( -->
<!--     data = d_sampled, -->
<!--     metric = "metrics_max_shannon_entropy", -->
<!--     feature = x -->
<!--     ) -->
<!-- }) -->
<!-- ``` -->

<!-- ## Variable Graph Features w.r.t Min Energy Gap -->

<!-- ```{r, echo=F, results=F} -->
<!-- vg_features <- d_sampled %>%  -->
<!--   select(contains("f_vg_")) %>%  -->
<!--   names() -->

<!-- lapply(vg_features, function(x){ -->
<!--   generate_feature_plot( -->
<!--     data = d_sampled, -->
<!--     metric = "metrics_min_energy_gap", -->
<!--     feature = x -->
<!--     ) -->
<!-- }) -->
<!-- ``` -->
